{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "import argparse\n",
    "import dataclasses\n",
    "import sys\n",
    "import timeit\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import click\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from home_robot.mapping.voxel import SparseVoxelMap\n",
    "from home_robot.utils.point_cloud_torch import unproject_masked_depth_to_xyz_coordinates\n",
    "\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_scene, get_camera_wireframe\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "def colormap_to_rgb_strings(data, colormap_name='viridis', include_alpha=False, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    Convert a range of numbers from a given dataset into a series of RGB or RGBA strings using a specified Matplotlib colormap.\n",
    "\n",
    "    :param data: The dataset from which to derive color mappings.\n",
    "    :param colormap_name: The name of the Matplotlib colormap to use.\n",
    "    :param include_alpha: Boolean to decide if the alpha channel should be included in the RGB strings.\n",
    "    :param min_val: Optional minimum value for colormap scaling.\n",
    "    :param max_val: Optional maximum value for colormap scaling.\n",
    "    :return: A list of color strings in the format 'rgb(R,G,B)' or 'rgba(R,G,B,A)'.\n",
    "    \"\"\"\n",
    "    # Compute min and max from the data if not provided\n",
    "    if min_val is None:\n",
    "        min_val = np.min(data)\n",
    "    if max_val is None:\n",
    "        max_val = np.max(data)\n",
    "\n",
    "    # Normalize data within the provided or computed min and max range\n",
    "    norm = plt.Normalize(min_val, max_val)\n",
    "    colors = plt.cm.get_cmap(colormap_name)(norm(data))\n",
    "\n",
    "    # Format color strings based on the include_alpha flag\n",
    "    if include_alpha:\n",
    "        return [\"rgba({},{},{},{})\".format(int(r*255), int(g*255), int(b*255), a) for r, g, b, a in colors]\n",
    "    else:\n",
    "        return [\"rgb({},{},{})\".format(int(r*255), int(g*255), int(b*255)) for r, g, b in colors[:, :3]]\n",
    "\n",
    "def add_camera_poses(\n",
    "    fig,\n",
    "    poses,\n",
    "    linewidth = 3,\n",
    "    color = None,\n",
    "    name = 'cam',\n",
    "    separate = True,\n",
    "    scale = 0.2,\n",
    "    colormap_name='plasma'\n",
    "    ):\n",
    "\n",
    "    \n",
    "    cam_points = get_camera_wireframe(scale)\n",
    "    # Convert p3d (opengl) to opencv\n",
    "    cam_points[:, 1] *= -1\n",
    "\n",
    "    if color is None:\n",
    "        colors = colormap_to_rgb_strings(list(range(len(poses))), colormap_name=colormap_name)\n",
    "    else:\n",
    "        colors = [color] * len(poses)\n",
    "    for i, (pose, color) in enumerate(zip(poses, colors)):\n",
    "        # cam_points[:, 2] *= -1\n",
    "        R = pose[:3, :3]\n",
    "        t = pose[:3, -1]\n",
    "        cam_points_world = cam_points @ R.T + t.unsqueeze(0)  # (cam_points @ R) # + t)\n",
    "        x, y, z = [v.cpu().numpy().tolist() for v in cam_points_world.unbind(1)]\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                z=z,\n",
    "                mode=\"lines\",\n",
    "                marker={\n",
    "                    \"size\": 1,\n",
    "                    \"color\": color,\n",
    "                },\n",
    "                line=dict(\n",
    "                    width=linewidth,\n",
    "                    color=color,\n",
    "                ),\n",
    "                name=f'{name}-{i}',\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from home_robot.datasets.eqa.dataset import EQADataset\n",
    "config_dict = dict(\n",
    "    dataset_name = 'eqa',\n",
    "    camera_params = dict(\n",
    "        image_height=1080,\n",
    "        image_width=1920,\n",
    "        # png_depth_scale = 1000.0 #for depth image in png format\n",
    "        png_depth_scale = 6553.5 #for depth image in png format\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = EQADataset(\n",
    "        config_dict,\n",
    "        # '/checkpoint/maksymets/eaif/datasets/eqa-v2/frames/scannet-v0/',\n",
    "        # '108-scannet-scene0354_00',\n",
    "        '/checkpoint/maksymets/eaif/datasets/eqa-v2/frames/hm3d-v0/',\n",
    "        '000-hm3d-BFRyYbPCCPE',\n",
    "        desired_height=480,\n",
    "        desired_width=853,\n",
    "        stride = 1,\n",
    "        device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_dataset = [dataset[i] for i in range(3)]\n",
    "short_dataset = [v for v in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, depth, Ks, pose = zip(*short_dataset)\n",
    "rgb, depth, Ks, pose = [torch.stack(v) for v in [rgb, depth, Ks, pose]]\n",
    "print(len(dataset))\n",
    "plt.imshow(rgb[0].cpu() / 255.)\n",
    "plt.show()\n",
    "plt.imshow(rgb[1].cpu() / 255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([[1., 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "v.inverse() - v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.structures import Pointclouds\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_scene, get_camera_wireframe\n",
    "from home_robot.utils.bboxes_3d_plotly import plot_scene_with_bboxes\n",
    "\n",
    "unprojected = unproject_masked_depth_to_xyz_coordinates(\n",
    "    # depth = depth[0, None].unsqueeze(1),\n",
    "    # pose = poses_opencv[0, None],\n",
    "    depth = depth.unsqueeze(1).squeeze(-1),\n",
    "    pose = pose,\n",
    "    inv_intrinsics = torch.linalg.inv(Ks)[:, :3, :3],\n",
    "    # mask: Optional[torch.Tensor] = None,\n",
    ") \n",
    "\n",
    "ptc = Pointclouds(\n",
    "    [unprojected.reshape(-1, 3)],\n",
    "    features = [rgb.reshape(-1,3) / 255.],\n",
    ").subsample(100000)\n",
    "\n",
    "fig = plot_scene({\n",
    "    \"global scene\": dict(\n",
    "        ptc=ptc\n",
    "    )\n",
    "    },\n",
    "    xaxis={\"backgroundcolor\":\"rgb(200, 200, 230)\"},\n",
    "    yaxis={\"backgroundcolor\":\"rgb(230, 200, 200)\"},\n",
    "    zaxis={\"backgroundcolor\":\"rgb(200, 230, 200)\"}, \n",
    "    axis_args=AxisArgs(showgrid=True),\n",
    "    pointcloud_marker_size=3,\n",
    "    pointcloud_max_points=200_000,\n",
    "    height=1000,\n",
    "    # width=1000,\n",
    ")\n",
    "\n",
    "add_camera_poses(fig, pose)\n",
    "fig.update_layout(\n",
    "    # width=width,\n",
    "    height=1000,\n",
    "    # aspectmode=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.rawpose[1]\n",
    "pose[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
